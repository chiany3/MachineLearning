{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Salinan dari FINAL EXAM MACHINE LEARNING_Paper 1(MNISTSIMPLECNN).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST SIMPLE CNN"
      ],
      "metadata": {
        "id": "vZ9yp8fTrHbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVYDSa2QYYwT",
        "outputId": "57877c09-746b-4810-80f7-283c0e5f9368"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EMA"
      ],
      "metadata": {
        "id": "fdMwoFAGrKm_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iWhMlVqxqeex"
      },
      "outputs": [],
      "source": [
        "#Proses Menjalankan EMA Class\n",
        "class EMA:\n",
        "    def __init__(self, model, decay): #Inisialisasi\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates):\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model): #proses penetapan parameter\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET"
      ],
      "metadata": {
        "id": "MzzR_AazrU3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library seperti torch,numpy,torchvision\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training=True, transform=None):\n",
        "        if training==True:\n",
        "            f = open('/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte', 'rb') #memanggil data dari drive\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        else:\n",
        "            f = open('/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
        "        ys = ys.astype(np.int)\n",
        "        self.x_data = xs\n",
        "        self.y_data = ys\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
        "        y = torch.tensor(np.array(self.y_data[idx]))\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y\n",
        "\n"
      ],
      "metadata": {
        "id": "PCoV8WmarW7-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSFORM"
      ],
      "metadata": {
        "id": "jQnhFFSxrdDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "import torchvision.transforms.functional as Z #import Transform\n",
        "\n",
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "    \n",
        "    @staticmethod #digunakan untuk memanggil fungsi secara langsung\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return Z.rotate(img, angle, False, False, None, None) #mengembalikan nilai\n"
      ],
      "metadata": {
        "id": "y-WOHhNLrfBF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MK3"
      ],
      "metadata": {
        "id": "r5EHG2Onri68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Proses pembuatan modelM3, untuk input pilihan logdir\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "kSniAIcjrmHZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MK5"
      ],
      "metadata": {
        "id": "Z7O-qPGfrj0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Proses pembuatan modelM5, untuk input pilihan logdir\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(96)\n",
        "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(128)\n",
        "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
        "        self.conv5_bn = nn.BatchNorm2d(160)\n",
        "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat5))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "OgvGrPaZr8ea"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MK7"
      ],
      "metadata": {
        "id": "ocFDd7Mwrkws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Proses pembuatan modelm7, untuk input pilihan logdir\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
        "        self.conv1_bn = nn.BatchNorm2d(48)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
        "        self.conv2_bn = nn.BatchNorm2d(96)\n",
        "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
        "        self.conv3_bn = nn.BatchNorm2d(144)\n",
        "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
        "        self.conv4_bn = nn.BatchNorm2d(192)\n",
        "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "1wtPrLl3r_eA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN"
      ],
      "metadata": {
        "id": "IpxbFJ-csQM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports library\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "#Running Proses Training\n",
        "def run(p_seed=0, p_epochs=150, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "    # random number generator seed \n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # kernel size model\n",
        "    KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "    # Nomor Epoch\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    # Pengguanaan dataset dari drive\n",
        "    if not os.path.exists(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/%s\"%p_logdir):\n",
        "        os.makedirs(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/%s\"%p_logdir)\n",
        "    OUTPUT_FILE = str(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
        "    MODEL_FILE = str(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
        "\n",
        "    # Menjalankan GPU\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data augmentation methods \n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # data loader \n",
        "    train_dataset = MnistDataset(training=True, transform=transform)\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # Seleksi Model\n",
        "    if(KERNEL_SIZE == 3):\n",
        "        model = ModelM3().to(device)\n",
        "    elif(KERNEL_SIZE == 5):\n",
        "        model = ModelM5().to(device)\n",
        "    elif(KERNEL_SIZE == 7):\n",
        "        model = ModelM7().to(device)\n",
        "\n",
        "    summary(model, (1, 28, 28))\n",
        "\n",
        "    # hyperparameter selection \n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    # Penghapusan data hasil\n",
        "    f = open(OUTPUT_FILE, 'w')\n",
        "    f.close()\n",
        "\n",
        "    # Variable global \n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "\n",
        "    # Pengulangan proses training dan evaluasi \n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # Proses Training                                                           #\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
        "\n",
        "       \n",
        "        # proses test                                                             \n",
        "       \n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_pred = np.zeros(0)\n",
        "        total_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
        "                total_target = np.append(total_target, target.cpu().numpy())\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            if(max_correct < correct):\n",
        "                torch.save(model.state_dict(), MODEL_FILE)\n",
        "                max_correct = correct\n",
        "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
        "        ema.resume(model)\n",
        "\n",
        "        # Output                    \n",
        "     \n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
        "\n",
        "        f = open(OUTPUT_FILE, 'a')\n",
        "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
        "        f.close()\n",
        "\n",
        "        \n",
        "        # update learning rate scheduler                                           \n",
        "        lr_scheduler.step()\n",
        "# seed, epoch, trial, gpu di input secara manual karena pada codingan sebelumnya diambil dari github sehingga tidak bisa dijalankan memakai code sebelumnya\n",
        "\n",
        "#seed untuk menentukan nilai awal\n",
        "p_seed = int(input (\"Seeds: \")) # memasukkan angka sebagai input seed\n",
        "\n",
        "#epoch digunakan untuk melakukan pengulangan (sesuai input) terhadap trial yang dijalankan\n",
        "p_epoch = int(input (\"Epoch: \")) # memasukkan angka sebagai input epoch\n",
        "\n",
        "#trial digunakan untuk pengulangan percobaan\n",
        "p_trials = int(input (\"Trials: \")) # memasukkan angka sebagai input epoch\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #memasukkan angka sebagai input epoch (disesuaikan dengan angka pada model)\n",
        "\n",
        "#gpu untuk menjalankan program pada grafik card\n",
        "p_gpu = int(input (\"GPU: \")) #masukkan angka sebagai input GPU\n",
        "\n",
        "p_logdir = input (\"Logdir: \") #masukkan input model yang akan digunakan\n",
        "\n",
        "#menjalankan GPU\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(p_gpu)\n",
        "\n",
        "for x in range (p_trials): #pengulangan percobaan (trial)\n",
        "  run(p_seed + x, p_epoch, p_kernel_size, p_logdir)\n"
      ],
      "metadata": {
        "id": "FiRN65aHsRPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36519e8-76f0-449c-ba80-70b6b2bc5f2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeds: 0\n",
            "Epoch: 10\n",
            "Trials: 10\n",
            "Kernel size: 3\n",
            "GPU: 0\n",
            "Logdir: modelM3\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.657581\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.644509\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.431458\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.324747\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.259744\n",
            "Best accuracy! correct images:  9837\n",
            "\n",
            "Test set: Average loss: 0.1619, Accuracy: 9837/10000 (98.37%) (best: 98.37%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.235940\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.210491\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.228506\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.151298\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167080\n",
            "Best accuracy! correct images:  9886\n",
            "\n",
            "Test set: Average loss: 0.0985, Accuracy: 9886/10000 (98.86%) (best: 98.86%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.127794\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.150670\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.130251\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.082413\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.131678\n",
            "\n",
            "Test set: Average loss: 0.1041, Accuracy: 9837/10000 (98.37%) (best: 98.86%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.106520\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.102702\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.096546\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.137737\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.134460\n",
            "Best accuracy! correct images:  9891\n",
            "\n",
            "Test set: Average loss: 0.0515, Accuracy: 9891/10000 (98.91%) (best: 98.91%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.089080\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.039457\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.159233\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.078115\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.101541\n",
            "Best accuracy! correct images:  9903\n",
            "\n",
            "Test set: Average loss: 0.0593, Accuracy: 9903/10000 (99.03%) (best: 99.03%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.036826\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.155474\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.067597\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.095855\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.062005\n",
            "Best accuracy! correct images:  9919\n",
            "\n",
            "Test set: Average loss: 0.0450, Accuracy: 9919/10000 (99.19%) (best: 99.19%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.081563\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.062785\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.099966\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.053231\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.048340\n",
            "\n",
            "Test set: Average loss: 0.0535, Accuracy: 9916/10000 (99.16%) (best: 99.19%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.077022\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.036999\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.041235\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.098196\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.031108\n",
            "\n",
            "Test set: Average loss: 0.0514, Accuracy: 9886/10000 (98.86%) (best: 99.19%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.033450\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.033347\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.066571\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.104280\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.013436\n",
            "Best accuracy! correct images:  9933\n",
            "\n",
            "Test set: Average loss: 0.0316, Accuracy: 9933/10000 (99.33%) (best: 99.33%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.081663\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.027163\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.062122\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.053770\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.084259\n",
            "Best accuracy! correct images:  9950\n",
            "\n",
            "Test set: Average loss: 0.0227, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.636028\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.647832\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.413704\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.371092\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.312717\n",
            "Best accuracy! correct images:  9855\n",
            "\n",
            "Test set: Average loss: 0.1321, Accuracy: 9855/10000 (98.55%) (best: 98.55%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.279296\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.204168\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.219688\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.138832\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.209977\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.0764, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.222111\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.198160\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.105505\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.105949\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.097200\n",
            "\n",
            "Test set: Average loss: 0.0640, Accuracy: 9882/10000 (98.82%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.129771\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.120033\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.138586\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.095951\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.059565\n",
            "\n",
            "Test set: Average loss: 0.0637, Accuracy: 9893/10000 (98.93%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.106627\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.104141\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.109954\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.082695\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.066076\n",
            "Best accuracy! correct images:  9935\n",
            "\n",
            "Test set: Average loss: 0.0500, Accuracy: 9935/10000 (99.35%) (best: 99.35%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.081759\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.062350\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.036390\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.068565\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.055213\n",
            "\n",
            "Test set: Average loss: 0.0434, Accuracy: 9911/10000 (99.11%) (best: 99.35%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.027435\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.067844\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.165016\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.100631\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.043272\n",
            "\n",
            "Test set: Average loss: 0.0366, Accuracy: 9924/10000 (99.24%) (best: 99.35%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.025664\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.027037\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.126853\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.061582\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.089322\n",
            "Best accuracy! correct images:  9939\n",
            "\n",
            "Test set: Average loss: 0.0279, Accuracy: 9939/10000 (99.39%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.072304\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.047984\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.024025\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.020876\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.040103\n",
            "\n",
            "Test set: Average loss: 0.1174, Accuracy: 9770/10000 (97.70%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.084903\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.046909\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.027359\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.021023\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.052601\n",
            "\n",
            "Test set: Average loss: 0.0378, Accuracy: 9917/10000 (99.17%) (best: 99.39%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.781280\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.692152\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.421331\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.367163\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.257468\n",
            "Best accuracy! correct images:  9903\n",
            "\n",
            "Test set: Average loss: 0.1202, Accuracy: 9903/10000 (99.03%) (best: 99.03%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.252424\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.193160\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.233927\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.214553\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.141100\n",
            "\n",
            "Test set: Average loss: 0.1153, Accuracy: 9847/10000 (98.47%) (best: 99.03%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.139321\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.246029\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.133498\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.132394\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.119488\n",
            "Best accuracy! correct images:  9916\n",
            "\n",
            "Test set: Average loss: 0.0648, Accuracy: 9916/10000 (99.16%) (best: 99.16%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.134954\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.118088\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.117211\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.131605\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.110608\n",
            "\n",
            "Test set: Average loss: 0.0752, Accuracy: 9908/10000 (99.08%) (best: 99.16%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.088950\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.119878\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.104338\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.062575\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.074147\n",
            "\n",
            "Test set: Average loss: 0.0526, Accuracy: 9896/10000 (98.96%) (best: 99.16%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.060501\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.099784\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.045697\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.078684\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.037615\n",
            "Best accuracy! correct images:  9931\n",
            "\n",
            "Test set: Average loss: 0.0401, Accuracy: 9931/10000 (99.31%) (best: 99.31%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.076354\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.038584\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.035968\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.064649\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.103038\n",
            "\n",
            "Test set: Average loss: 0.0537, Accuracy: 9902/10000 (99.02%) (best: 99.31%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.057977\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.033324\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.067285\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.023938\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.039615\n",
            "Best accuracy! correct images:  9942\n",
            "\n",
            "Test set: Average loss: 0.0267, Accuracy: 9942/10000 (99.42%) (best: 99.42%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.086950\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.076146\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.053447\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.073173\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.018065\n",
            "\n",
            "Test set: Average loss: 0.0588, Accuracy: 9879/10000 (98.79%) (best: 99.42%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.094665\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.063347\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.026867\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.096968\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.067503\n",
            "\n",
            "Test set: Average loss: 0.0395, Accuracy: 9915/10000 (99.15%) (best: 99.42%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.845584\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.734352\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.437420\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.326101\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.247609\n",
            "Best accuracy! correct images:  9885\n",
            "\n",
            "Test set: Average loss: 0.1193, Accuracy: 9885/10000 (98.85%) (best: 98.85%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.216039\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.256882\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.280726\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.194597\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.140175\n",
            "\n",
            "Test set: Average loss: 0.1018, Accuracy: 9880/10000 (98.80%) (best: 98.85%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.186126\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.136455\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.108124\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.074210\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.144340\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.0642, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.071753\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.145950\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.105642\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.091366\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.082137\n",
            "Best accuracy! correct images:  9927\n",
            "\n",
            "Test set: Average loss: 0.0493, Accuracy: 9927/10000 (99.27%) (best: 99.27%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.062197\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.120297\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.080788\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.126620\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.091405\n",
            "\n",
            "Test set: Average loss: 0.0468, Accuracy: 9926/10000 (99.26%) (best: 99.27%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.043135\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.081558\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.052101\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.095565\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.090906\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0314, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.060068\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.079037\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.090488\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.149981\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.064171\n",
            "\n",
            "Test set: Average loss: 0.0414, Accuracy: 9916/10000 (99.16%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.163638\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.180105\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.018359\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.074644\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.038348\n",
            "\n",
            "Test set: Average loss: 0.0406, Accuracy: 9917/10000 (99.17%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.040033\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.109288\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.046035\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.029140\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.055925\n",
            "Best accuracy! correct images:  9949\n",
            "\n",
            "Test set: Average loss: 0.0242, Accuracy: 9949/10000 (99.49%) (best: 99.49%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.123827\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.024680\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.032425\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.049376\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.024074\n",
            "\n",
            "Test set: Average loss: 0.0252, Accuracy: 9942/10000 (99.42%) (best: 99.49%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.558000\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.653399\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.420209\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381024\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.298903\n",
            "Best accuracy! correct images:  9863\n",
            "\n",
            "Test set: Average loss: 0.1451, Accuracy: 9863/10000 (98.63%) (best: 98.63%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.319992\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.284144\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.230777\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.164753\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167446\n",
            "Best accuracy! correct images:  9900\n",
            "\n",
            "Test set: Average loss: 0.0762, Accuracy: 9900/10000 (99.00%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.149612\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.145609\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.162328\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.117442\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.118292\n",
            "\n",
            "Test set: Average loss: 0.0714, Accuracy: 9898/10000 (98.98%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.149527\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.141583\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.095074\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.153903\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.078501\n",
            "\n",
            "Test set: Average loss: 0.0531, Accuracy: 9892/10000 (98.92%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.119296\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.168053\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.069165\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.072366\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.123790\n",
            "\n",
            "Test set: Average loss: 0.1034, Accuracy: 9799/10000 (97.99%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.102470\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.068896\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.070841\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.048174\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.059310\n",
            "\n",
            "Test set: Average loss: 0.0485, Accuracy: 9883/10000 (98.83%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.062143\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.102418\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.094362\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.119238\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.042054\n",
            "Best accuracy! correct images:  9923\n",
            "\n",
            "Test set: Average loss: 0.0365, Accuracy: 9923/10000 (99.23%) (best: 99.23%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.105992\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.076473\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.053850\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.058642\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.050086\n",
            "Best accuracy! correct images:  9941\n",
            "\n",
            "Test set: Average loss: 0.0268, Accuracy: 9941/10000 (99.41%) (best: 99.41%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.093252\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.053234\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.091019\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.037479\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.063136\n",
            "\n",
            "Test set: Average loss: 0.0415, Accuracy: 9904/10000 (99.04%) (best: 99.41%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.064008\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.024237\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.057032\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.034912\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.062785\n",
            "\n",
            "Test set: Average loss: 0.0285, Accuracy: 9935/10000 (99.35%) (best: 99.41%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.686705\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.636909\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.500591\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.399536\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.265424\n",
            "Best accuracy! correct images:  9876\n",
            "\n",
            "Test set: Average loss: 0.1297, Accuracy: 9876/10000 (98.76%) (best: 98.76%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.291581\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.230881\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.211286\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.244806\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.189460\n",
            "Best accuracy! correct images:  9908\n",
            "\n",
            "Test set: Average loss: 0.0717, Accuracy: 9908/10000 (99.08%) (best: 99.08%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.156650\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.175611\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.153027\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.102010\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.172819\n",
            "Best accuracy! correct images:  9919\n",
            "\n",
            "Test set: Average loss: 0.0579, Accuracy: 9919/10000 (99.19%) (best: 99.19%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.082733\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.107878\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.137950\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.132370\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.134464\n",
            "\n",
            "Test set: Average loss: 0.0517, Accuracy: 9910/10000 (99.10%) (best: 99.19%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.068503\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.132361\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.151496\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.042199\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.086636\n",
            "Best accuracy! correct images:  9926\n",
            "\n",
            "Test set: Average loss: 0.0381, Accuracy: 9926/10000 (99.26%) (best: 99.26%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.076532\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.080748\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.112639\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.108302\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.097141\n",
            "\n",
            "Test set: Average loss: 0.0452, Accuracy: 9913/10000 (99.13%) (best: 99.26%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.123889\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.107375\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.117692\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.042292\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.054257\n",
            "\n",
            "Test set: Average loss: 0.0395, Accuracy: 9915/10000 (99.15%) (best: 99.26%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.038821\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.054192\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.105297\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.037437\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.018675\n",
            "\n",
            "Test set: Average loss: 0.0730, Accuracy: 9794/10000 (97.94%) (best: 99.26%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.163745\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.073082\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.036221\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.076724\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.069739\n",
            "\n",
            "Test set: Average loss: 0.0373, Accuracy: 9920/10000 (99.20%) (best: 99.26%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.085635\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.021672\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.055591\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.082918\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.036077\n",
            "\n",
            "Test set: Average loss: 0.0442, Accuracy: 9891/10000 (98.91%) (best: 99.26%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.687867\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.579472\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.444794\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.340334\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.255302\n",
            "Best accuracy! correct images:  9837\n",
            "\n",
            "Test set: Average loss: 0.1457, Accuracy: 9837/10000 (98.37%) (best: 98.37%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.203337\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.210760\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.236550\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.151624\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.123923\n",
            "Best accuracy! correct images:  9910\n",
            "\n",
            "Test set: Average loss: 0.0637, Accuracy: 9910/10000 (99.10%) (best: 99.10%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.157810\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.133131\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.144132\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.133007\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.166987\n",
            "Best accuracy! correct images:  9917\n",
            "\n",
            "Test set: Average loss: 0.0574, Accuracy: 9917/10000 (99.17%) (best: 99.17%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.114605\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.107641\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.106079\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.055837\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.176933\n",
            "Best accuracy! correct images:  9930\n",
            "\n",
            "Test set: Average loss: 0.0451, Accuracy: 9930/10000 (99.30%) (best: 99.30%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.175254\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.056164\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.161829\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.057681\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.058873\n",
            "\n",
            "Test set: Average loss: 0.0524, Accuracy: 9882/10000 (98.82%) (best: 99.30%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.074384\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.096577\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.096232\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.053072\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.091877\n",
            "Best accuracy! correct images:  9947\n",
            "\n",
            "Test set: Average loss: 0.0253, Accuracy: 9947/10000 (99.47%) (best: 99.47%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.059565\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.049555\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.040543\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.031681\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.078674\n",
            "\n",
            "Test set: Average loss: 0.0408, Accuracy: 9938/10000 (99.38%) (best: 99.47%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.066159\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.058700\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.049518\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.065824\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.045034\n",
            "\n",
            "Test set: Average loss: 0.0499, Accuracy: 9894/10000 (98.94%) (best: 99.47%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.045858\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.059529\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.078350\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.068147\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.023550\n",
            "\n",
            "Test set: Average loss: 0.0225, Accuracy: 9945/10000 (99.45%) (best: 99.47%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.020161\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.055028\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.103033\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.037368\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.020799\n",
            "\n",
            "Test set: Average loss: 0.0307, Accuracy: 9938/10000 (99.38%) (best: 99.47%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.718870\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.616919\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.373682\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.393186\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.342804\n",
            "Best accuracy! correct images:  9876\n",
            "\n",
            "Test set: Average loss: 0.1063, Accuracy: 9876/10000 (98.76%) (best: 98.76%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.248759\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.194025\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.206126\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.224371\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.151690\n",
            "Best accuracy! correct images:  9910\n",
            "\n",
            "Test set: Average loss: 0.0720, Accuracy: 9910/10000 (99.10%) (best: 99.10%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.188264\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.122034\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.232183\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.092729\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.111592\n",
            "\n",
            "Test set: Average loss: 0.0835, Accuracy: 9854/10000 (98.54%) (best: 99.10%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.145894\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.097020\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.101744\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.111585\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.084964\n",
            "Best accuracy! correct images:  9939\n",
            "\n",
            "Test set: Average loss: 0.0287, Accuracy: 9939/10000 (99.39%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.152180\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.088264\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.134480\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.077312\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.049327\n",
            "\n",
            "Test set: Average loss: 0.0556, Accuracy: 9881/10000 (98.81%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.050612\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.149206\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.051450\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.112168\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.041074\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 9926/10000 (99.26%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.084393\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.043663\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.066180\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.096592\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.102542\n",
            "\n",
            "Test set: Average loss: 0.0321, Accuracy: 9930/10000 (99.30%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.057870\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.071811\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.059686\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.026780\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.031729\n",
            "\n",
            "Test set: Average loss: 0.0571, Accuracy: 9902/10000 (99.02%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.031557\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.116234\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.086318\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.060883\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.067913\n",
            "\n",
            "Test set: Average loss: 0.0429, Accuracy: 9921/10000 (99.21%) (best: 99.39%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.057218\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.058194\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.039351\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.011120\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.029485\n",
            "Best accuracy! correct images:  9951\n",
            "\n",
            "Test set: Average loss: 0.0209, Accuracy: 9951/10000 (99.51%) (best: 99.51%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.680449\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.786845\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.447232\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.361637\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.271602\n",
            "Best accuracy! correct images:  9897\n",
            "\n",
            "Test set: Average loss: 0.1178, Accuracy: 9897/10000 (98.97%) (best: 98.97%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.226681\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.177364\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.178418\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.233710\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.114331\n",
            "\n",
            "Test set: Average loss: 0.0838, Accuracy: 9887/10000 (98.87%) (best: 98.97%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.138514\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.140366\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.141777\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.099439\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.095588\n",
            "Best accuracy! correct images:  9902\n",
            "\n",
            "Test set: Average loss: 0.0688, Accuracy: 9902/10000 (99.02%) (best: 99.02%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.144013\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.092014\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.064050\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.190085\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.208516\n",
            "\n",
            "Test set: Average loss: 0.0657, Accuracy: 9901/10000 (99.01%) (best: 99.02%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.104785\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.087060\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.034646\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.085055\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.084418\n",
            "Best accuracy! correct images:  9931\n",
            "\n",
            "Test set: Average loss: 0.0388, Accuracy: 9931/10000 (99.31%) (best: 99.31%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.056238\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.091465\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.050355\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.049864\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.098430\n",
            "\n",
            "Test set: Average loss: 0.0365, Accuracy: 9925/10000 (99.25%) (best: 99.31%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.061436\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.048448\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.039832\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.041504\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.042250\n",
            "\n",
            "Test set: Average loss: 0.0435, Accuracy: 9900/10000 (99.00%) (best: 99.31%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.071150\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.032012\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.029093\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.053061\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.113170\n",
            "\n",
            "Test set: Average loss: 0.0401, Accuracy: 9914/10000 (99.14%) (best: 99.31%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.048747\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.076863\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.035214\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.046037\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.075798\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0396, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.027563\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.067222\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.042801\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.079773\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.047690\n",
            "Best accuracy! correct images:  9939\n",
            "\n",
            "Test set: Average loss: 0.0304, Accuracy: 9939/10000 (99.39%) (best: 99.39%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.802870\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.648436\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.517613\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.352464\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.269446\n",
            "Best accuracy! correct images:  9856\n",
            "\n",
            "Test set: Average loss: 0.1308, Accuracy: 9856/10000 (98.56%) (best: 98.56%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.278275\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.215296\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.252302\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.209931\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.133129\n",
            "Best accuracy! correct images:  9875\n",
            "\n",
            "Test set: Average loss: 0.0959, Accuracy: 9875/10000 (98.75%) (best: 98.75%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.157762\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.182860\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.200853\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.161770\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.093586\n",
            "Best accuracy! correct images:  9884\n",
            "\n",
            "Test set: Average loss: 0.0737, Accuracy: 9884/10000 (98.84%) (best: 98.84%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.179962\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.113950\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.081638\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.165497\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.116856\n",
            "\n",
            "Test set: Average loss: 0.0736, Accuracy: 9861/10000 (98.61%) (best: 98.84%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.090008\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.169721\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.080947\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.103359\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.105342\n",
            "Best accuracy! correct images:  9900\n",
            "\n",
            "Test set: Average loss: 0.0599, Accuracy: 9900/10000 (99.00%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.109784\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.046094\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.042871\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.101040\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.044977\n",
            "Best accuracy! correct images:  9932\n",
            "\n",
            "Test set: Average loss: 0.0362, Accuracy: 9932/10000 (99.32%) (best: 99.32%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.050291\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.062423\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.111072\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.047452\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.073782\n",
            "\n",
            "Test set: Average loss: 0.0388, Accuracy: 9914/10000 (99.14%) (best: 99.32%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.035257\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.066487\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.123202\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.048855\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.017689\n",
            "\n",
            "Test set: Average loss: 0.0410, Accuracy: 9910/10000 (99.10%) (best: 99.32%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.097863\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.041348\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.025716\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.064514\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.041791\n",
            "\n",
            "Test set: Average loss: 0.0419, Accuracy: 9906/10000 (99.06%) (best: 99.32%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.026914\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.078460\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.034916\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.089499\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.091231\n",
            "\n",
            "Test set: Average loss: 0.0425, Accuracy: 9901/10000 (99.01%) (best: 99.32%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "2j1tiYElt3nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports \n",
        "import sys\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "#Running Proses Testing\n",
        "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "\n",
        "    # enable GPU usage \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data loader \n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection \n",
        "    if(p_kernel_size == 3):\n",
        "        model1 = ModelM3().to(device)\n",
        "    elif(p_kernel_size == 5):\n",
        "        model1 = ModelM5().to(device)\n",
        "    elif(p_kernel_size == 7):\n",
        "        model1 = ModelM7().to(device)\n",
        "\n",
        "    model1.load_state_dict(torch.load(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,p_seed))) #load data dari drive\n",
        "\n",
        "    model1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model1(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
        "\n",
        "    np.savetxt(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")\n",
        "    print(len(wrong_images), wrong_images)\n",
        "\n",
        "p_logdir = input (\"Logdir: \") #masukkan input model yang akan digunakan\n",
        "p_seed = int(input (\"Seeds: \")) # input angka untuk seed\n",
        "p_trials = int(input (\"Trials: \")) # masukkan angka sebagi input berapa kali percobaan\n",
        "p_kernel_size = int (input (\"Kernel size: \")) # masukkan angka sebagai input ukuran kernel (menyesuaikan angka pada model)\n",
        "\n",
        "for y in range (p_trials): #perulangan percobaan (trial)\n",
        "  run(p_seed + y, p_kernel_size, p_logdir)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pnP281bFt21-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2b6642-57ae-42c1-edea-bb00d11d77af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logdir: modelM3\n",
            "Seeds: 0\n",
            "Trials: 10\n",
            "Kernel size: 3\n",
            "50 [321, 359, 449, 582, 882, 938, 947, 1112, 1114, 1226, 1232, 1260, 1328, 1621, 1716, 1901, 1911, 2040, 2130, 2266, 2293, 2462, 2597, 3073, 3225, 3266, 3762, 3976, 4018, 4699, 4736, 4740, 4761, 5745, 5955, 6554, 6576, 6625, 6651, 8275, 8279, 8316, 8408, 8527, 9009, 9024, 9505, 9729, 9754, 9850]\n",
            "61 [321, 412, 447, 582, 625, 674, 1014, 1226, 1232, 1299, 1393, 1737, 1748, 1901, 1911, 1940, 2035, 2040, 2118, 2130, 2135, 2266, 2447, 2454, 2462, 2597, 2654, 2930, 3365, 3422, 3475, 3534, 3558, 3762, 3846, 4065, 4571, 4699, 4860, 4911, 5937, 6554, 6558, 6571, 6576, 6597, 6625, 6847, 8275, 8279, 8325, 8527, 9009, 9638, 9664, 9679, 9693, 9698, 9729, 9811, 9839]\n",
            "58 [193, 359, 447, 582, 625, 674, 1226, 1232, 1247, 1260, 1299, 1393, 1621, 1737, 1901, 1911, 1940, 2035, 2040, 2118, 2130, 2135, 2293, 2454, 2462, 2597, 2654, 3030, 3073, 3365, 3422, 3534, 3558, 3762, 4699, 4761, 4823, 5265, 5937, 6571, 6576, 6599, 6625, 6847, 7441, 8275, 8279, 8316, 8387, 8408, 8527, 9009, 9505, 9664, 9679, 9698, 9729, 9754]\n",
            "51 [8, 193, 321, 359, 582, 625, 674, 1061, 1112, 1232, 1260, 1299, 1393, 1621, 1737, 1901, 1911, 2035, 2040, 2130, 2293, 2462, 2597, 2686, 3475, 3534, 3762, 4443, 4571, 4761, 4860, 5937, 6554, 6576, 6597, 6625, 6783, 7216, 8275, 8279, 8316, 8325, 8527, 9009, 9505, 9664, 9669, 9729, 9749, 9754, 9850]\n",
            "59 [115, 193, 247, 447, 449, 582, 726, 938, 947, 1039, 1112, 1226, 1260, 1328, 1901, 1903, 2035, 2040, 2130, 2135, 2293, 2447, 2462, 2532, 2695, 2771, 2823, 3225, 3384, 3422, 3534, 3762, 4007, 4018, 4053, 4547, 4551, 4699, 4740, 4783, 4860, 6558, 6576, 6597, 6599, 6625, 8000, 8279, 8316, 8408, 8527, 9009, 9015, 9505, 9679, 9693, 9698, 9729, 9754]\n",
            "74 [104, 247, 321, 445, 447, 449, 582, 938, 947, 956, 1050, 1112, 1178, 1226, 1232, 1247, 1438, 1527, 1737, 1878, 1901, 1911, 2040, 2118, 2130, 2148, 2266, 2293, 2338, 2447, 2454, 2462, 2597, 2771, 2939, 3062, 3073, 3225, 3330, 3365, 3422, 3534, 3726, 3941, 4092, 4176, 4201, 4284, 4443, 4699, 4740, 4860, 5888, 5937, 6172, 6554, 6555, 6576, 6625, 8000, 8095, 8275, 8279, 8408, 8527, 9009, 9015, 9664, 9669, 9672, 9679, 9698, 9729, 9792]\n",
            "53 [359, 445, 447, 582, 625, 965, 1226, 1232, 1260, 1299, 1393, 1737, 1901, 2035, 2040, 2118, 2130, 2293, 2338, 2454, 2597, 2654, 3030, 3073, 3225, 3365, 3422, 3534, 3762, 3821, 4201, 4699, 4761, 4823, 4860, 5937, 6554, 6558, 6576, 6597, 6599, 6625, 7216, 8279, 8408, 8527, 9009, 9015, 9505, 9679, 9698, 9729, 9888]\n",
            "49 [193, 359, 449, 582, 625, 938, 1114, 1232, 1260, 1299, 1393, 1621, 1737, 1901, 1911, 2040, 2118, 2130, 2293, 2462, 2597, 2654, 3225, 3558, 3762, 4018, 4176, 4201, 4284, 4443, 4504, 4740, 4761, 5165, 5955, 6576, 6625, 6651, 6783, 6847, 7216, 8275, 8279, 8316, 8408, 8527, 9664, 9729, 9754]\n",
            "61 [8, 282, 358, 359, 449, 582, 659, 726, 938, 1039, 1045, 1226, 1232, 1260, 1508, 1621, 1716, 1737, 1901, 2040, 2063, 2098, 2130, 2293, 2462, 2654, 3213, 3225, 3266, 3384, 3534, 3762, 3821, 3976, 4027, 4053, 4284, 4443, 4551, 4699, 4740, 4761, 4823, 5745, 5937, 6243, 6576, 6599, 6625, 6651, 8275, 8279, 8325, 8527, 9009, 9024, 9505, 9679, 9729, 9754, 9850]\n",
            "68 [8, 321, 445, 447, 468, 582, 625, 938, 947, 1226, 1260, 1299, 1328, 1393, 1621, 1737, 1847, 1901, 1911, 1940, 2035, 2040, 2118, 2130, 2135, 2148, 2237, 2293, 2433, 2447, 2454, 2462, 2488, 2597, 2654, 2686, 2771, 2930, 3073, 3225, 3365, 3412, 3422, 3534, 3762, 4196, 4699, 4740, 4860, 4911, 5833, 5937, 6554, 6576, 6597, 6625, 8061, 8275, 8279, 8408, 8527, 9009, 9679, 9698, 9729, 9754, 9792, 9839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOMO-ENSEMBLE"
      ],
      "metadata": {
        "id": "h3SKnMmyuAMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import argparse\n",
        "\n",
        "cnt = 1\n",
        "best = 10000\n",
        "curr = 10000\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input ukuran kernel \n",
        "\n",
        "KERNEL_SIZE = p_kernel_size #menyamakan variabel\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(i+1,10):\n",
        "        for k in range(j+1,10):\n",
        "            w1 = np.loadtxt(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, i)).astype(np.int)\n",
        "            w2 = np.loadtxt(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, j)).astype(np.int)\n",
        "            w3 = np.loadtxt(\"/content/drive/MyDrive/FX_ML/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, k)).astype(np.int)\n",
        "\n",
        "            board = np.zeros((10000))\n",
        "            board[w1] += 1\n",
        "            board[w2] += 1\n",
        "            board[w3] += 1\n",
        "            board = board // 2\n",
        "            curr = np.sum(board)\n",
        "            if curr < best:\n",
        "                best = curr\n",
        "            print(\"%4d %4d %4d %4d %4d %4d\"%(cnt, len(w1), len(w2), len(w3), curr, best))\n",
        "            cnt += 1\n"
      ],
      "metadata": {
        "id": "KOoEhXfQuBdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7321025-5f40-4522-8684-4c1403ead9af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel size: 3\n",
            "   1   50   61   58   53   53\n",
            "   2   50   61   51   45   45\n",
            "   3   50   61   59   47   45\n",
            "   4   50   61   74   43   43\n",
            "   5   50   61   53   47   43\n",
            "   6   50   61   49   46   43\n",
            "   7   50   61   61   45   43\n",
            "   8   50   61   68   55   43\n",
            "   9   50   58   51   42   42\n",
            "  10   50   58   59   45   42\n",
            "  11   50   58   74   49   42\n",
            "  12   50   58   53   48   42\n",
            "  13   50   58   49   46   42\n",
            "  14   50   58   61   46   42\n",
            "  15   50   58   68   52   42\n",
            "  16   50   51   59   43   42\n",
            "  17   50   51   74   45   42\n",
            "  18   50   51   53   43   42\n",
            "  19   50   51   49   46   42\n",
            "  20   50   51   61   46   42\n",
            "  21   50   51   68   48   42\n",
            "  22   50   59   74   47   42\n",
            "  23   50   59   53   45   42\n",
            "  24   50   59   49   39   39\n",
            "  25   50   59   61   48   39\n",
            "  26   50   59   68   46   39\n",
            "  27   50   74   53   49   39\n",
            "  28   50   74   49   47   39\n",
            "  29   50   74   61   49   39\n",
            "  30   50   74   68   50   39\n",
            "  31   50   53   49   45   39\n",
            "  32   50   53   61   46   39\n",
            "  33   50   53   68   52   39\n",
            "  34   50   49   61   45   39\n",
            "  35   50   49   68   45   39\n",
            "  36   50   61   68   48   39\n",
            "  37   61   58   51   56   39\n",
            "  38   61   58   59   53   39\n",
            "  39   61   58   74   49   39\n",
            "  40   61   58   53   54   39\n",
            "  41   61   58   49   49   39\n",
            "  42   61   58   61   50   39\n",
            "  43   61   58   68   54   39\n",
            "  44   61   51   59   49   39\n",
            "  45   61   51   74   47   39\n",
            "  46   61   51   53   49   39\n",
            "  47   61   51   49   47   39\n",
            "  48   61   51   61   46   39\n",
            "  49   61   51   68   54   39\n",
            "  50   61   59   74   51   39\n",
            "  51   61   59   53   45   39\n",
            "  52   61   59   49   50   39\n",
            "  53   61   59   61   46   39\n",
            "  54   61   59   68   54   39\n",
            "  55   61   74   53   49   39\n",
            "  56   61   74   49   50   39\n",
            "  57   61   74   61   43   39\n",
            "  58   61   74   68   56   39\n",
            "  59   61   53   49   48   39\n",
            "  60   61   53   61   46   39\n",
            "  61   61   53   68   50   39\n",
            "  62   61   49   61   44   39\n",
            "  63   61   49   68   54   39\n",
            "  64   61   61   68   52   39\n",
            "  65   58   51   59   46   39\n",
            "  66   58   51   74   52   39\n",
            "  67   58   51   53   53   39\n",
            "  68   58   51   49   42   39\n",
            "  69   58   51   61   44   39\n",
            "  70   58   51   68   54   39\n",
            "  71   58   59   74   53   39\n",
            "  72   58   59   53   50   39\n",
            "  73   58   59   49   50   39\n",
            "  74   58   59   61   47   39\n",
            "  75   58   59   68   53   39\n",
            "  76   58   74   53   52   39\n",
            "  77   58   74   49   54   39\n",
            "  78   58   74   61   48   39\n",
            "  79   58   74   68   55   39\n",
            "  80   58   53   49   53   39\n",
            "  81   58   53   61   46   39\n",
            "  82   58   53   68   52   39\n",
            "  83   58   49   61   49   39\n",
            "  84   58   49   68   51   39\n",
            "  85   58   61   68   50   39\n",
            "  86   51   59   74   51   39\n",
            "  87   51   59   53   45   39\n",
            "  88   51   59   49   44   39\n",
            "  89   51   59   61   47   39\n",
            "  90   51   59   68   51   39\n",
            "  91   51   74   53   53   39\n",
            "  92   51   74   49   48   39\n",
            "  93   51   74   61   44   39\n",
            "  94   51   74   68   57   39\n",
            "  95   51   53   49   44   39\n",
            "  96   51   53   61   45   39\n",
            "  97   51   53   68   51   39\n",
            "  98   51   49   61   45   39\n",
            "  99   51   49   68   47   39\n",
            " 100   51   61   68   46   39\n",
            " 101   59   74   53   51   39\n",
            " 102   59   74   49   49   39\n",
            " 103   59   74   61   48   39\n",
            " 104   59   74   68   53   39\n",
            " 105   59   53   49   49   39\n",
            " 106   59   53   61   47   39\n",
            " 107   59   53   68   51   39\n",
            " 108   59   49   61   44   39\n",
            " 109   59   49   68   48   39\n",
            " 110   59   61   68   48   39\n",
            " 111   74   53   49   53   39\n",
            " 112   74   53   61   50   39\n",
            " 113   74   53   68   53   39\n",
            " 114   74   49   61   41   39\n",
            " 115   74   49   68   56   39\n",
            " 116   74   61   68   51   39\n",
            " 117   53   49   61   46   39\n",
            " 118   53   49   68   50   39\n",
            " 119   53   61   68   52   39\n",
            " 120   49   61   68   42   39\n"
          ]
        }
      ]
    }
  ]
}